{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc9b6bb-d005-4c9e-b7f5-71025cd69cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pygame\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84c0939-5b4c-46e6-9579-da627f49b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pygame for sound playback\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"C:/Users/kiran yadav/Downloads/mixkit-classic-alarm-995.wav\")\n",
    "\n",
    "# MediaPipe face mesh\n",
    "fp = mp.solutions.face_mesh\n",
    "fm_model = fp.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Constants\n",
    "CLOSED_EYE_THRESH = 0.15 # minimum eye threshold value when it open is 0.20 but this video purpose iam taken this value\n",
    "YAWN_THRESH = 0.6\n",
    "YAWN_COOLDOWN = 4\n",
    "\n",
    "yawn_count = 0\n",
    "last_yawn_time = 0\n",
    "eye_closed_start = None\n",
    "\n",
    "# style for connections\n",
    "simple_style = mp.solutions.drawing_utils.DrawingSpec(color=(193, 166, 144), thickness=1, circle_radius=1)\n",
    "\n",
    "def get_landmark(frame, landmarks, idx):\n",
    "    h, w, _ = frame.shape\n",
    "    lm = landmarks[idx]\n",
    "    return np.array([lm.x * w, lm.y * h])\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = fm_model.process(rgb)\n",
    "    \n",
    "    current_time = time.time()\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(image=frame,\n",
    "                                                 landmark_list = results.multi_face_landmarks[0],\n",
    "                                                 connections = fp.FACEMESH_LEFT_EYE.union(fp.FACEMESH_RIGHT_EYE).union(fp.FACEMESH_LIPS),\n",
    "                                                 landmark_drawing_spec=None,\n",
    "                                                 connection_drawing_spec = simple_style)\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # EAR (Eye Aspect Ratio)\n",
    "        def EAR(p1, p2, p3, p4, p5, p6):\n",
    "            A = np.linalg.norm(get_landmark(frame, landmarks, p2) - get_landmark(frame, landmarks, p6))\n",
    "            B = np.linalg.norm(get_landmark(frame, landmarks, p3) - get_landmark(frame, landmarks, p5))\n",
    "            C = np.linalg.norm(get_landmark(frame, landmarks, p1) - get_landmark(frame, landmarks, p4))\n",
    "            return (A + B) / (2.0 * C)\n",
    "\n",
    "        left_eye = EAR(362, 385, 387, 263, 373, 380)\n",
    "        right_eye = EAR(33, 160, 158, 133, 153, 144)\n",
    "        avg_ear = (left_eye + right_eye) / 2.0\n",
    "\n",
    "        # MAR (Mouth Aspect Ratio) for yawn\n",
    "        A = np.linalg.norm(get_landmark(frame, landmarks, 81) - get_landmark(frame, landmarks, 178))\n",
    "        B = np.linalg.norm(get_landmark(frame, landmarks, 13) - get_landmark(frame, landmarks, 14))\n",
    "        C = np.linalg.norm(get_landmark(frame, landmarks, 311) - get_landmark(frame, landmarks, 308))\n",
    "        D = np.linalg.norm(get_landmark(frame, landmarks, 61) - get_landmark(frame, landmarks, 291))\n",
    "        mar = (A + B + C) / (2.0 * D)\n",
    "\n",
    "        # Yawn Detection\n",
    "        if mar > YAWN_THRESH and (current_time - last_yawn_time > YAWN_COOLDOWN):\n",
    "            yawn_count += 1\n",
    "            last_yawn_time = current_time\n",
    "\n",
    "\n",
    "        # Alarm for long eye closure\n",
    "        if avg_ear < CLOSED_EYE_THRESH:\n",
    "            if eye_closed_start is None:\n",
    "                eye_closed_start = current_time\n",
    "            elif current_time - eye_closed_start >= 2:\n",
    "                if not pygame.mixer.music.get_busy():\n",
    "                    pygame.mixer.music.play()\n",
    "                cv2.putText(frame, \"Wake Up!\", (30, 180),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "        else:\n",
    "            eye_closed_start = None\n",
    "            if pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.stop()\n",
    "            cv2.putText(frame, \"AWAKE\", (30, 180),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "        # Draw values\n",
    "        cv2.putText(frame, f'EAR: {avg_ear:.2f}', (30, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'MAR: {mar:.2f}', (30, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f'Yawns: {yawn_count}', (30, 140),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Drowsiness Detection\", frame)\n",
    "\n",
    "    # Exit\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.mixer.music.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6fa8b-df12-47ea-88e9-34206dd4a61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
